#! /usr/bin/env python
# Compatibility: Python 3.x

import requests
import re
from urllib.parse import urljoin


class Scanner:
    def __init__(self, url, ignored_links):
        self.session = requests.Session()
        self.target_url = url
        self.target_links = []
        self.links_to_ignore = ignored_links

    def extract_links_from(self, url):
        response = self.session.get(url)
        return re.findall('href="(.*?)"', response.content.decode(errors="ignore"))

    def crawl(self, url=None):
        if url is None:
            url = self.target_url

        href_links = self.extract_links_from(url)

        for link in href_links:
            link = urljoin(url, link)

            if "#" in link:
                link = link.split("#")[0]

            # Check for repeated links and links that lead to external websites (outside our targeted web app scope).
            if self.target_url in link and link not in self.target_links and link not in self.links_to_ignore:
                self.target_links.append(link)
                print(link)
                self.crawl(link)


# To avoid creating separate file just to run the Keylogg class, we put the following if statement.
# This check ensures that the lines below are only executed when this script is run directly (and not imported)
# The code below basically requires you to know where is the logout page,
# where is the login page on the website and the attributes of HTML form. Customization is mandatory.
if __name__ == "__main__":
    target_url = "http://10.0.2.4/dvwa/"
    links_to_ignore = ["http://10.0.2.4/dvwa/logout.php"]

    login_data = {"username": "admin", "password": "password", "Login": "submit"}

    vulnerability_scanner = Scanner(target_url, links_to_ignore)
    # The line below logs the user in, allowing for more links to be crawled.
    vulnerability_scanner.session.post("http://10.0.2.4/dvwa/login.php", data=login_data)
    vulnerability_scanner.crawl()
